{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-03-09T17:51:08.505332Z","iopub.execute_input":"2023-03-09T17:51:08.505722Z","iopub.status.idle":"2023-03-09T17:51:08.544374Z","shell.execute_reply.started":"2023-03-09T17:51:08.505677Z","shell.execute_reply":"2023-03-09T17:51:08.543262Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/jigsaw-toxic-comment-classification-challenge/sample_submission.csv\n/kaggle/input/jigsaw-toxic-comment-classification-challenge/test_labels.csv\n/kaggle/input/jigsaw-toxic-comment-classification-challenge/train.csv\n/kaggle/input/jigsaw-toxic-comment-classification-challenge/test.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install transformers clean-text","metadata":{"execution":{"iopub.status.busy":"2023-03-09T17:51:10.081772Z","iopub.execute_input":"2023-03-09T17:51:10.082450Z","iopub.status.idle":"2023-03-09T17:51:24.368813Z","shell.execute_reply.started":"2023-03-09T17:51:10.082399Z","shell.execute_reply":"2023-03-09T17:51:24.367612Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.7/site-packages (4.26.1)\nCollecting clean-text\n  Downloading clean_text-0.6.0-py3-none-any.whl (11 kB)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (23.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers) (2.28.2)\nRequirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.12.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (2021.11.10)\nRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.13.2)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers) (4.64.1)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (6.0)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers) (4.11.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers) (3.9.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (1.21.6)\nCollecting ftfy<7.0,>=6.0\n  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting emoji<2.0.0,>=1.0.0\n  Downloading emoji-1.7.0.tar.gz (175 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m175.4/175.4 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: wcwidth>=0.2.5 in /opt/conda/lib/python3.7/site-packages (from ftfy<7.0,>=6.0->clean-text) (0.2.6)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.4.0)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers) (3.11.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2.1.1)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (1.26.14)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2022.12.7)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (3.4)\nBuilding wheels for collected packages: emoji\n  Building wheel for emoji (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for emoji: filename=emoji-1.7.0-py3-none-any.whl size=171046 sha256=5ec5a489095d1d04874cce00743d1a8c5d4d66b19a4e400e1ff47021b016b369\n  Stored in directory: /root/.cache/pip/wheels/b9/c6/29/f04340b92ea4bc94de18767d2a215768a86e7115ac471ca82e\nSuccessfully built emoji\nInstalling collected packages: emoji, ftfy, clean-text\n  Attempting uninstall: emoji\n    Found existing installation: emoji 2.2.0\n    Uninstalling emoji-2.2.0:\n      Successfully uninstalled emoji-2.2.0\nSuccessfully installed clean-text-0.6.0 emoji-1.7.0 ftfy-6.1.1\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"train_path = '/kaggle/input/jigsaw-toxic-comment-classification-challenge/train.csv'\n\ndata = pd.read_csv(train_path)","metadata":{"execution":{"iopub.status.busy":"2023-03-09T17:51:42.549294Z","iopub.execute_input":"2023-03-09T17:51:42.549708Z","iopub.status.idle":"2023-03-09T17:51:44.448913Z","shell.execute_reply.started":"2023-03-09T17:51:42.549647Z","shell.execute_reply":"2023-03-09T17:51:44.447847Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"print('Number of Records: {}, Number of features/columns: {}'.format(data.shape[0], data.shape[1]))","metadata":{"execution":{"iopub.status.busy":"2023-03-09T17:51:53.291957Z","iopub.execute_input":"2023-03-09T17:51:53.292331Z","iopub.status.idle":"2023-03-09T17:51:53.298690Z","shell.execute_reply.started":"2023-03-09T17:51:53.292299Z","shell.execute_reply":"2023-03-09T17:51:53.297698Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Number of Records: 159571, Number of features/columns: 8\n","output_type":"stream"}]},{"cell_type":"code","source":"print('Null values: {}'.format(data.isnull().values.sum()))","metadata":{"execution":{"iopub.status.busy":"2023-03-09T17:52:01.961702Z","iopub.execute_input":"2023-03-09T17:52:01.962418Z","iopub.status.idle":"2023-03-09T17:52:01.997796Z","shell.execute_reply.started":"2023-03-09T17:52:01.962379Z","shell.execute_reply":"2023-03-09T17:52:01.996159Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Null values: 0\n","output_type":"stream"}]},{"cell_type":"code","source":"target_columns = list(data.columns)[2:]\ny_labels = data[target_columns].values","metadata":{"execution":{"iopub.status.busy":"2023-03-09T17:52:10.070158Z","iopub.execute_input":"2023-03-09T17:52:10.070742Z","iopub.status.idle":"2023-03-09T17:52:10.087511Z","shell.execute_reply.started":"2023-03-09T17:52:10.070687Z","shell.execute_reply":"2023-03-09T17:52:10.086452Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"from transformers import DistilBertTokenizer, DistilBertConfig, TFDistilBertModel\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\nfrom tqdm import tqdm\nfrom cleantext import clean","metadata":{"execution":{"iopub.status.busy":"2023-03-09T17:52:18.990605Z","iopub.execute_input":"2023-03-09T17:52:18.991069Z","iopub.status.idle":"2023-03-09T17:52:30.045213Z","shell.execute_reply.started":"2023-03-09T17:52:18.991030Z","shell.execute_reply":"2023-03-09T17:52:30.044082Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"distil_bert = 'distilbert-base-uncased'\n\ntokenizer = DistilBertTokenizer.from_pretrained(distil_bert, do_lower_case=True, add_special_tokens=True,\n                                                max_length=128, pad_to_max_length=True)","metadata":{"execution":{"iopub.status.busy":"2023-03-09T17:52:31.471435Z","iopub.execute_input":"2023-03-09T17:52:31.472073Z","iopub.status.idle":"2023-03-09T17:52:34.070065Z","shell.execute_reply.started":"2023-03-09T17:52:31.472030Z","shell.execute_reply":"2023-03-09T17:52:34.069096Z"},"trusted":true},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fe14da7994e744c0a3cebf2b3670b0d9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"918f818c494a4a6e850051f6d5d12f01"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8d161cb43c7448cfa16545075ab7f0a3"}},"metadata":{}}]},{"cell_type":"code","source":"def cleaning(text):\n    return clean(text, no_line_breaks=True, no_urls=True, no_punct=True)\n\ndef tokenize(sentences, tokenizer):\n    \n    input_ids = []\n    input_masks = []\n    \n    for sentence in tqdm(sentences):\n        inputs = tokenizer.encode_plus(sentence, add_special_tokens=True, \n                                       max_length=128, pad_to_max_length=True, \n                                       return_attention_mask=True, return_token_type_ids=True)\n        \n        input_ids.append(inputs['input_ids'])\n        input_masks.append(inputs['attention_mask'])       \n        \n    return np.asarray(input_ids, dtype='int32'),np.asarray(input_masks, dtype='int32')","metadata":{"execution":{"iopub.status.busy":"2023-03-09T17:52:45.502919Z","iopub.execute_input":"2023-03-09T17:52:45.503288Z","iopub.status.idle":"2023-03-09T17:52:45.511005Z","shell.execute_reply.started":"2023-03-09T17:52:45.503255Z","shell.execute_reply":"2023-03-09T17:52:45.509872Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"data['comment_text'] = data['comment_text'].apply(cleaning)\ninput_ids, input_masks = tokenize(data['comment_text'], tokenizer)","metadata":{"execution":{"iopub.status.busy":"2023-03-09T17:52:54.952933Z","iopub.execute_input":"2023-03-09T17:52:54.953921Z","iopub.status.idle":"2023-03-09T17:59:22.813095Z","shell.execute_reply.started":"2023-03-09T17:52:54.953861Z","shell.execute_reply":"2023-03-09T17:59:22.812033Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stderr","text":"  0%|          | 0/159571 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n/opt/conda/lib/python3.7/site-packages/transformers/tokenization_utils_base.py:2345: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n  FutureWarning,\n100%|██████████| 159571/159571 [05:22<00:00, 494.24it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"config = DistilBertConfig(dropout=0.2, attention_dropout=0.2)\n\nconfig.output_hidden_states = False\n\ntransformer_model = TFDistilBertModel.from_pretrained(distil_bert, config=config)\n\ninput_ids_in = tf.keras.layers.Input(shape=(128,), name='input_token', dtype='int32')\ninput_masks_in = tf.keras.layers.Input(shape=(128,), name='masked_token', dtype='int32')\n\nembedding_layer = transformer_model(input_ids_in, attention_mask=input_masks_in)[0]\nX = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(50, \n                                                       return_sequences=True, \n                                                       dropout=0.1, \n                                                       recurrent_dropout=0.1))(embedding_layer)\nX = tf.keras.layers.GlobalMaxPool1D()(X)\nX = tf.keras.layers.Dense(50, activation='relu')(X)\nX = tf.keras.layers.Dropout(0.2)(X)\nX = tf.keras.layers.Dense(6, activation='sigmoid')(X)\n\nmodel = tf.keras.models.Model(inputs=[input_ids_in, input_masks_in], outputs=X)\n\nfor layer in model.layers[:3]:\n    layer.trainable = False","metadata":{"execution":{"iopub.status.busy":"2023-03-09T18:02:55.139967Z","iopub.execute_input":"2023-03-09T18:02:55.140891Z","iopub.status.idle":"2023-03-09T18:03:08.226286Z","shell.execute_reply.started":"2023-03-09T18:02:55.140851Z","shell.execute_reply":"2023-03-09T18:03:08.225245Z"},"trusted":true},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)\"tf_model.h5\";:   0%|          | 0.00/363M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c8376e1975f84e4da13dd4df0718b1f5"}},"metadata":{}},{"name":"stderr","text":"Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertModel: ['activation_13', 'vocab_projector', 'vocab_layer_norm', 'vocab_transform']\n- This IS expected if you are initializing TFDistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing TFDistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nAll the layers of TFDistilBertModel were initialized from the model checkpoint at distilbert-base-uncased.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n","output_type":"stream"}]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2023-03-09T18:03:12.167874Z","iopub.execute_input":"2023-03-09T18:03:12.168262Z","iopub.status.idle":"2023-03-09T18:03:12.209736Z","shell.execute_reply.started":"2023-03-09T18:03:12.168228Z","shell.execute_reply":"2023-03-09T18:03:12.208894Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Model: \"model\"\n__________________________________________________________________________________________________\n Layer (type)                   Output Shape         Param #     Connected to                     \n==================================================================================================\n input_token (InputLayer)       [(None, 128)]        0           []                               \n                                                                                                  \n masked_token (InputLayer)      [(None, 128)]        0           []                               \n                                                                                                  \n tf_distil_bert_model (TFDistil  TFBaseModelOutput(l  66362880   ['input_token[0][0]',            \n BertModel)                     ast_hidden_state=(N               'masked_token[0][0]']           \n                                one, 128, 768),                                                   \n                                 hidden_states=None                                               \n                                , attentions=None)                                                \n                                                                                                  \n bidirectional (Bidirectional)  (None, 128, 100)     327600      ['tf_distil_bert_model[0][0]']   \n                                                                                                  \n global_max_pooling1d (GlobalMa  (None, 100)         0           ['bidirectional[0][0]']          \n xPooling1D)                                                                                      \n                                                                                                  \n dense (Dense)                  (None, 50)           5050        ['global_max_pooling1d[0][0]']   \n                                                                                                  \n dropout_19 (Dropout)           (None, 50)           0           ['dense[0][0]']                  \n                                                                                                  \n dense_1 (Dense)                (None, 6)            306         ['dropout_19[0][0]']             \n                                                                                                  \n==================================================================================================\nTotal params: 66,695,836\nTrainable params: 332,956\nNon-trainable params: 66,362,880\n__________________________________________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2023-03-09T18:03:21.212605Z","iopub.execute_input":"2023-03-09T18:03:21.213331Z","iopub.status.idle":"2023-03-09T18:03:21.482692Z","shell.execute_reply.started":"2023-03-09T18:03:21.213281Z","shell.execute_reply":"2023-03-09T18:03:21.481699Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"X_train_id, X_test_id, X_train_mask, X_test_mask, y_train, y_test = train_test_split(input_ids, \n                                                                                     input_masks, \n                                                                                     y_labels,\n                                                                                     test_size=0.2, \n                                                                                     random_state=42)","metadata":{"execution":{"iopub.status.busy":"2023-03-09T18:03:33.967522Z","iopub.execute_input":"2023-03-09T18:03:33.967900Z","iopub.status.idle":"2023-03-09T18:03:34.065758Z","shell.execute_reply.started":"2023-03-09T18:03:33.967868Z","shell.execute_reply":"2023-03-09T18:03:34.064714Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"hist = model.fit([X_train_id, X_train_mask], \n                 y_train, \n                 validation_data=([X_test_id, X_test_mask], y_test),\n                 epochs=1,\n                 batch_size=64)","metadata":{"execution":{"iopub.status.busy":"2023-03-09T18:03:42.571498Z","iopub.execute_input":"2023-03-09T18:03:42.572206Z","iopub.status.idle":"2023-03-09T18:41:36.373420Z","shell.execute_reply.started":"2023-03-09T18:03:42.572168Z","shell.execute_reply":"2023-03-09T18:41:36.372426Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"1995/1995 [==============================] - 2274s 1s/step - loss: 14.2360 - accuracy: 0.3341 - val_loss: 22.9310 - val_accuracy: 0.0689\n","output_type":"stream"}]},{"cell_type":"code","source":"model.save_weights('toxic.h5')","metadata":{"execution":{"iopub.status.busy":"2023-03-09T18:41:46.191663Z","iopub.execute_input":"2023-03-09T18:41:46.192359Z","iopub.status.idle":"2023-03-09T18:41:46.755898Z","shell.execute_reply.started":"2023-03-09T18:41:46.192321Z","shell.execute_reply":"2023-03-09T18:41:46.754872Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"sample_text = 'I hate you, you idiot!'\nclean_txt = cleaning(sample_text)\ninput_ids_test, input_masks_test = tokenize(clean_txt, tokenizer)","metadata":{"execution":{"iopub.status.busy":"2023-03-09T18:41:56.933536Z","iopub.execute_input":"2023-03-09T18:41:56.934047Z","iopub.status.idle":"2023-03-09T18:41:56.949322Z","shell.execute_reply.started":"2023-03-09T18:41:56.934008Z","shell.execute_reply":"2023-03-09T18:41:56.948268Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stderr","text":"100%|██████████| 20/20 [00:00<00:00, 4662.41it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"preds = model.predict([input_ids_test, input_masks_test])[0]\nprediction = target_columns[np.argmax(preds, axis=0)]\nprint(prediction)","metadata":{"execution":{"iopub.status.busy":"2023-03-09T18:42:10.949827Z","iopub.execute_input":"2023-03-09T18:42:10.950520Z","iopub.status.idle":"2023-03-09T18:42:13.505993Z","shell.execute_reply.started":"2023-03-09T18:42:10.950484Z","shell.execute_reply":"2023-03-09T18:42:13.505040Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"1/1 [==============================] - 2s 2s/step\ntoxic\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}